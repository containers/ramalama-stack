name: Test External Providers

on:
  workflow_dispatch:
  push:
    branches:
      - main
    paths:
      - 'src/ramalama_stack/**'
      - 'tests/**'
      - '.github/workflows/test-external-providers.yml'
      - pyproject.toml
      - requirements.txt
      - uv.lock
  pull_request:
    branches:
      - main
    paths:
      - 'src/ramalama_stack/**'
      - 'tests/**'
      - '.github/workflows/test-external-providers.yml'
      - pyproject.toml
      - requirements.txt
      - uv.lock

env:
  LC_ALL: en_US.UTF-8

defaults:
  run:
    shell: bash

permissions:
  contents: read

jobs:
  test-external-providers:
    name: test-external-providers
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        inference_model:
          - 'llama3.2:3b'
          - 'granite3.2:2b'
    env:
      INFERENCE_MODEL: ${{ matrix.inference_model }}
    steps:
      - name: Harden Runner
        uses: step-security/harden-runner@f4a75cfd619ee5ce8d5b864b0d183aff3c69b55a # v2.13.1
        with:
          egress-policy: audit

      - name: Set INFERENCE_MODEL_NO_COLON for logging artifacts
        run: echo "INFERENCE_MODEL_NO_COLON=$(echo "$INFERENCE_MODEL" | tr ':' '_')" >> $GITHUB_ENV

      - name: Checkout containers/ramalama-stack
        uses: actions/checkout@08c6903cd8c0fde910a37f88322edcfb5dd907a8 # v5.0.0
        with:
          # https://github.com/actions/checkout/issues/249
          fetch-depth: 0

      - name: Install uv
        uses: astral-sh/setup-uv@eb1897b8dc4b5d5bfe39a428a8f2304605e0983c # v7.0.0
        with:
          python-version: "3.12"

      - name: Set Up Environment and Install Dependencies
        run: |
          uv sync

          # temporary hack for file writing that should be done by the pip setup script
          # https://github.com/containers/ramalama-stack/issues/53
          mkdir -p ~/.llama/distributions/ramalama/
          cp -r $GITHUB_WORKSPACE/src/ramalama_stack/providers.d/ ~/.llama/
          cp $GITHUB_WORKSPACE/src/ramalama_stack/ramalama-run.yaml ~/.llama/distributions/ramalama/ramalama-run.yaml

      - name: Run 'test-build.sh'
        run: $GITHUB_WORKSPACE/tests/test-build.sh

      - name: Cache Ramalama store
        id: ramalama-store-cache
        uses: actions/cache@0057852bfaa89a56745cba8c7296529d2fc39830 # v4.3.0
        with:
          path: ~/.local/share/ramalama
          key: ramalama-store-${{ env.INFERENCE_MODEL }}

      - name: Download model to serve with Ramalama
        if: ${{ steps.ramalama-store-cache.outputs.cache-hit != 'true' }}
        run: uv run ramalama pull ${{ env.INFERENCE_MODEL }}

      - name: Run 'test-external-providers.sh'
        run: $GITHUB_WORKSPACE/tests/test-external-providers.sh

      - name: Run 'test-rag.sh'
        run: $GITHUB_WORKSPACE/tests/test-rag.sh

      - name: Upload logs
        uses: actions/upload-artifact@ea165f8d65b6e75b540449e92b4886f43607fa02 # v4.6.2
        if: always()
        with:
          name: logs-test-external-providers-${{ env.INFERENCE_MODEL_NO_COLON }}
          retention-days: 5
          path: |
            **/*.log
